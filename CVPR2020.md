# CVPR2020最新信息及论文下载贴（Papers/Codes/Project/PaperReading／Demos/直播分享／论文分享会等）


官网链接：http://cvpr2020.thecvf.com/<br>
时间：Seattle, Washington，2020年6月14日-6月19日<br>
论文接收公布时间：2020年2月24日<br>

相关问题：
* [如何评价2020年计算机视觉顶会CVPR投稿量破万的现象?](https://www.zhihu.com/question/356099725/)<br>
* [如何评价 CVPR 2020的论文接收结果？有哪些亮点论文？](https://www.zhihu.com/question/372070853)<br><br>



# 1.CVPR2020接收论文（持续更新）<br>




**70.Watch your Up-Convolution: CNN Based Generative Deep Neural Networks are Failing to Reproduce Spectral Distributions** （视觉常识）<br>
论文链接：https://arxiv.org/abs/2003.01826<br>
作者：Ricard Durall, Margret Keuper, Janis Keuper<br><br>

**69.Self-training with Noisy Student improves ImageNet classification**（图像分类）<br>
论文链接：https://arxiv.org/abs/1911.04252<br>
作者：Qizhe Xie, Minh-Thang Luong, Eduard Hovy, Quoc V. Le<br><br>

**68.Disentangling Physical Dynamics from Unknown Factors for Unsupervised Video Prediction**（无监督/视频预测）<br>
论文链接：https://arxiv.org/abs/2003.01460<br>
作者：Vincent Le Guen, Nicolas Thome<br><br>

**67.Image Matching across Wide Baselines: From Paper to Practice**（图像匹配）<br>
论文链接：https://arxiv.org/abs/2003.01587<br>
作者：Yuhe Jin, Dmytro Mishkin, Anastasiia Mishchuk, Jiri Matas, Pascal Fua, Kwang Moo Yi, Eduard Trulls<br><br>

**66.Transferring Dense Pose to Proximal Animal Classes**<br>
论文链接：https://arxiv.org/abs/2003.00080<br>
作者：Artsiom Sanakoyeu, Vasil Khalidov, Maureen S. McCarthy, Andrea Vedaldi, Natalia Neverova<br><br>

**65.SketchGCN: Semantic Sketch Segmentation with Graph Convolutional Networks**（GCN/语义分割）<br>
论文链接：https://arxiv.org/abs/2003.00678<br>
作者：Lumin Yang, Jiajie Zhuang, Hongbo Fu, Kun Zhou, Youyi Zheng<br><br>

**64.Say As You Wish: Fine-grained Control of Image Caption Generation with Abstract Scene Graphs**（视频分析）<br>
论文链接：https://arxiv.org/abs/2003.00387<br>
作者：Shizhe Chen, Qin Jin, Peng Wang, Qi Wu<br><br>

**63.Fine-grained Video-Text Retrieval with Hierarchical Graph Reasoning**（视频分析）<br>
论文链接：https://arxiv.org/abs/2003.00392<br>
作者：Shizhe Chen, Yida Zhao, Qin Jin, Qi Wu<br><br>

**62.4D Association Graph for Realtime Multi-person Motion Capture Using Multiple Video Cameras**（姿态估计）<br>
论文链接：https://arxiv.org/abs/2002.12625<br>
作者：Yuxiang Zhang, Liang An, Tao Yu, Xiu Li, Kun Li, Yebin Liu<br><br>

**61.Representations, Metrics and Statistics For Shape Analysis of Elastic Graphs**（视觉常识）<br>
论文链接：https://arxiv.org/abs/2003.00287<br>
作者：Xiaoyang Guo, Anuj Srivastava<br><br>

**60.GPU-Accelerated Mobile Multi-view Style Transfer**（模型加速）<br>
论文链接：https://arxiv.org/abs/2003.00706<br>
作者：Puneet Kohli, Saravana Gunaseelan, Jason Orozco, Yiwen Hua, Edward Li, Nicolas Dahlquist<br><br>

**59.Learning in the Frequency Domain**（视觉常识）<br>
论文链接：https://arxiv.org/abs/2002.12416<br>
作者：Kai Xu, Minghai Qin, Fei Sun, Yuhao Wang, Yen-kuang Chen, Fengbo Ren<br><br>

**58.Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution**（超分辨率）<br>
论文链接：https://arxiv.org/abs/2002.11616<br>
作者：Xiaoyu Xiang, Yapeng Tian, Yulun Zhang, Yun Fu, Jan P. Allebach, Chenliang Xu<br><br>

**57.Learning to Shade Hand-drawn Sketches**（图像处理）<br>
论文链接：https://arxiv.org/abs/2002.11812<br>
作者：Qingyuan Zheng, Zhuoru Li, Adam Bargteil<br><br>

**56.Cross-modality Person re-identification with Shared-Specific Feature Transfer**（行人重识别）<br>
论文链接：https://arxiv.org/abs/2002.12489<br>
作者：Yan Lu, Yue Wu, Bin Liu, Tianzhu Zhang, Baopu Li, Qi Chu, Nenghai Yu<br><br>

**55.RandLA-Net: Efficient Semantic Segmentation of Large-Scale Point Clouds**（三维/语义分割）<br>
论文链接：https://arxiv.org/abs/1911.11236<br>
代码：https://github.com/QingyongHu/RandLA-Net<br><br>

**54.Few-Shot Object Detection with Attention-RPN and Multi-Relation Detector**（目标检测）<br>
论文链接：https://arxiv.org/abs/1908.01998<br>
作者：Qi Fan, Wei Zhuo, Chi-Keung Tang, Yu-Wing Tai<br>
论文解读：https://mp.weixin.qq.com/s/eOJi8Aeg-39FojtuCnpjQQ<br><br>

**53.The Garden of Forking Paths: Towards Multi-Future Trajectory Prediction**（轨迹预测）<br>
论文链接：https://arxiv.org/pdf/1912.06445.pdf<br>
作者：Junwei Liang, Lu Jiang, Kevin Murphy, Ting Yu, Alexander Hauptmann<br><br>

**52.Sketch Less for More: On-the-Fly Fine-Grained Sketch Based Image Retrieval**（图像检索）<br>
论文链接：https://arxiv.org/abs/2002.10310<br>
作者：Ayan Kumar Bhunia, Yongxin Yang, Timothy M. Hospedales, Tao Xiang, Yi-Zhe Song<br><br>

**51.Filter Grafting for Deep Neural Networks**（视觉常识）<br>
论文链接：https://arxiv.org/pdf/2001.05868.pdf<br>
作者：Fanxu Meng, Hao Cheng2, Ke Li, Zhixin Xu, Rongrong Ji, Xing Sun, Gaungming Lu<br><br>

**50.Single Image Reflection Removal through Cascaded Refinement**<br>
论文链接：https://arxiv.org/abs/1911.06634<br>
作者：Chao Li, Yixiao Yang, Kun He, Stephen Lin, John E. Hopcroft<br><br>

**49.Rethinking the Route Towards Weakly Supervised Object Localization**<br>
论文链接：https://arxiv.org/abs/2002.11359<br>
作者：Chen-Lin Zhang, Yun-Hao Cao, Jianxin Wu<br><br>

**48.Object Relational Graph with Teacher-Recommended Learning for Video Captioning**（视频分析）<br>
论文链接：https://arxiv.org/abs/2002.11566<br>
作者：Ziqi Zhang, Yaya Shi, Chunfeng Yuan, Bing Li, Peijin Wang, Weiming Hu, Zhengjun Zha<br><br>

**47.Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution**（视频分析）<br>
论文链接：https://arxiv.org/abs/2002.11616<br>
作者：Xiaoyu Xiang, Yapeng Tian, Yulun Zhang, Yun Fu, Jan P. Allebach, Chenliang Xu<br><br>

**46.ClusterFit: Improving Generalization of Visual Representations**(视觉常识)<br>
论文链接：https://arxiv.org/abs/1912.03330<br>
作者：Xueting Yan, Ishan Misra, Abhinav Gupta, Deepti Ghadiyaram, Dhruv Mahajan<br><br>

**45.Towards Universal Representation Learning for Deep Face Recognition**（人脸识别）<br>
论文链接：https://arxiv.org/abs/2002.11841<br>
作者：Yichun Shi, Xiang Yu, Kihyuk Sohn, Manmohan Chandraker, Anil K. Jain<br><br>

**44. Towards Universal Representation Learning for Deep Face Recognition**<br>
论文链接：https://arxiv.org/abs/2002.11841<br>
作者：Yichun Shi, Xiang Yu, Kihyuk Sohn, Manmohan Chandraker, Anil K. Jain<br><br>

**43. Social-STGCNN: A Social Spatio-Temporal Graph Convolutional Neural Network for Human Trajectory Prediction**<br>
论文链接：https://arxiv.org/abs/2002.11927<br>
作者：Abduallah Mohamed, Kun Qian, Mohamed Elhoseiny, Christian Claudel<br><br>

**42. Auto-Encoding Twin-Bottleneck Hashing**<br>
论文链接：https://arxiv.org/abs/2002.11930<br>
作者：Yuming Shen, Jie Qin, Jiaxin Chen, Mengyang Yu, Li Liu, Fan Zhu, Fumin Shen, Ling Shao<br><br>

**41.Unbiased Scene Graph Generation from Biased Training**(视觉常识)<br>
论文链接：https://arxiv.org/abs/2002.11949<br>
作者：Kaihua Tang, Yulei Niu, Jianqiang Huang, Jiaxin Shi, Hanwang Zhang<br><br>

**40. Total3DUnderstanding: Joint Layout, Object Pose and Mesh Reconstruction for Indoor Scenes from a Single Image**（三维）<br>
论文链接：https://arxiv.org/abs/2002.12212<br>
作者：Yinyu Nie, Xiaoguang Han, Shihui Guo, Yujian Zheng, Jian Chang, Jian Jun Zhang<br><br>

**39. Meta-Transfer Learning for Zero-Shot Super-Resolution**（零样本）<br>
论文链接：https://arxiv.org/abs/2002.12213<br>
作者：Jae Woong Soh, Sunwoo Cho, Nam Ik Cho<br><br>

**38. Blurry Video Frame Interpolation**（视频分析）<br>
论文链接：https://arxiv.org/abs/2002.12259<br>
作者：Wang Shen, Wenbo Bao, Guangtao Zhai, Li Chen, Xiongkuo Min, Zhiyong Gao<br><br>

**37. Generalized ODIN: Detecting Out-of-distribution Image without Learning from Out-of-distribution Data**（图像检测）<br>
论文链接：https://arxiv.org/abs/2002.11297<br>
作者：Yen-Chang Hsu, Yilin Shen, Hongxia Jin, Zsolt Kira<br><br>

**36. Visual Commonsense R-CNN**（视觉常识）<br>
论文链接：https://arxiv.org/abs/2002.12204<br>
作者：Tan Wang, Jianqiang Huang, Hanwang Zhang, Qianru Sun<br><br>

**35. Deep Image Harmonization via Domain Verification**（图像处理）<br>
论文链接：https://arxiv.org/abs/1911.13239<br>
作者：Wenyan Cong, Jianfu Zhang, Li Niu, Liu Liu, Zhixin Ling, Weiyuan Li, Liqing Zhang<br>
开源代码：https://github.com/bcmi/Image_Harmonization_Datasets<br>
论文解读：https://mp.weixin.qq.com/s/JgQ7bgc_bfgWE-PmJMKtOA<br><br>

**34. Robust Design of Deep Neural Networks against Adversarial Attacks based on Lyapunov Theory	**	<br>
论文链接：https://arxiv.org/abs/1911.04636	<br>
作者：Arash Rahnama, Andre T. Nguyen, Edward Raff<br><br>

**33. Optimal least-squares solution to the hand-eye calibration problem**（姿态估计）	<br>
论文链接：https://arxiv.org/abs/2002.10838	<br>
作者：Amit Dekel, Linus Härenstam-Nielsen, Sergio Caccamo<br><br>

**32. On Positive-Unlabeled Classification in GAN**（GAN） <br><br>			

**31. Your Local GAN: Designing Two Dimensional Local Attention Mechanisms for Generative Models**	（GAN）	<br>
论文链接：https://arxiv.org/abs/1911.12287	<br>
作者：Giannis Daras, Augustus Odena, Han Zhang<br>
代码：https://github.com/giannisdaras/ylg<br><br>

**30. MSG-GAN: Multi-Scale Gradient GAN for Stable Image Synthesis**（GAN）	<br>
论文链接：https://arxiv.org/abs/1903.06048	<br>
作者：Animesh Karnewar, Oliver Wang	<br><br>

**29. A Semi-Supervised Assessor of Neural Architectures**（半监督）		<br><br>

**28. ROAM: Recurrently Optimizing Tracking Model	**（目标跟踪）	<br>
论文链接：https://arxiv.org/abs/1907.12006	<br>
作者：Tianyu Yang, Pengfei Xu, Runbo Hu, Hua Chai, Antoni B. Chan	<br><br>

**27. Hit-Detector: Hierarchical Trinity Architecture Search for Object Detection**（目标检测）			<br><br>

**26. Learning deep network for detecting 3D object keypoints and 6D poses**	（目标检测；三维）			<br><br>

**25. Suppressing Uncertainties for Large-Scale Facial Expression Recognition**（人脸识别）	<br>
论文链接：https://arxiv.org/abs/2002.10392	<br>
作者：Kai Wang, Xiaojiang Peng	<br>
代码：https://github.com/kaiwang960112/Self-Cure-Network<br><br>

**24. NestedVAE: Isolating Common Factors via Weak Supervision**（弱监督）	<br>
论文链接：https://arxiv.org/abs/2002.11576	<br>
作者：Matthew J. Vowels, Necati Cihan Camgoz, Richard Bowden	<br><br>

**23. Frequency Domain Compact 3D Convolutional Neural Networks** （三维）		<br><br>	

**22. Learning multiview 3D point cloud registration**（三维）	<br>
论文链接：https://arxiv.org/abs/2001.05119	<br>
作者：Zan Gojcic, Caifa Zhou, Jan D. Wegner	<br><br>

**21. In Perfect Shape: Certifiably Optimal 3D Shape Reconstruction from 2D Landmarks**（三维）	<br>
论文链接：https://arxiv.org/abs/1911.11924	<br>
作者：Heng Yang and Luca Carlone	<br><br><br>

**20. Action Modifiers:Learning from Adverbs in Instructional Video**（视频分析）	<br>
论文链接：https://arxiv.org/abs/1912.06617		<br><br>

**19. A General and Adaptive Robust Loss Function**（损失函数）	<br>
论文链接：https://arxiv.org/abs/1701.03077	<br>
作者：Jonathan T. Barron	<br><br>

**18. A Characteristic Function Approach to Deep Implicit Generative Modeling**（特征函数）<br>	
论文链接：https://arxiv.org/abs/1909.07425	<br>
作者：Abdul Fatir Ansari, Jonathan Scarlett, Harold Soh	<br><br>

**17. AdderNet: Do We Really Need Multiplications in Deep Learning?** （视觉常识）	<br>
论文链接：https://arxiv.org/pdf/1912.13200	<br>
作者：Hanting Chen, Yunhe Wang, Chunjing Xu	<br><br>

**16. What it Thinks is Important is Important: Robustness Transfers through Input Gradients**（视觉常识）	<br>
论文链接：https://arxiv.org/abs/1912.05699	<br>
作者：Alvin Chan, Yi Tay, Yew-Soon Ong	<br><br>

**15. 12-in-1: Multi-Task Vision and Language Representation Learning**	（视觉常识）	<br>
论文链接：https://arxiv.org/abs/1912.02315	<br>
作者：Jiasen Lu, Vedanuj Goswami, Marcus Rohrbach, Devi Parikh, Stefan Lee	<br>
论文解读：https://mp.weixin.qq.com/s/8CvUT9JvnysIXay7vyY16w<br><br>

**14. Making Better Mistakes: Leveraging Class Hierarchies with Deep Networks**（视觉常识）	<br>
论文链接：https://arxiv.org/abs/1912.09393	<br>
作者：Luca Bertinetto, Romain Mueller, Konstantinos Tertikas, Sina Samangooei, Nicholas A. Lord	<br><br>

**13. GhostNet: More Features from Cheap Operations**（轻量卷积神经网络）	<br>
论文链接：https://arxiv.org/pdf/1911.11907	<br>
作者：Kai Han, Yunhe Wang, Qi Tian1	<br>
代码：https://github.com/iamhankai/ghostnet<br>
论文解读：https://zhuanlan.zhihu.com/p/109325275<br><br>

**12. CARS: Contunuous Evolution for Efficient Neural Architecture Search**（神经结构搜索）	<br>
论文链接：https://arxiv.org/abs/1909.04977	<br>
作者：Zhaohui Yang1, Yunhe Wang, Xinghao Chen	<br>
代码：https://github.com/huawei-noah/CARS<br><br>

**11. Rethinking Performance Estimation in Neural Architecture Search**（神经结构搜索）	<br><br>		

**10. RoutedFusion: Learning Real-time Depth Map Fusion**（图像处理）	<br>
论文链接：https://arxiv.org/pdf/2001.04388.pdf	<br>
作者：Silvan Weder, Johannes Scho ̈nberger	<br><br>

**9. PolarMask: Single Shot Instance Segmentation with Polar Representation**（图像分割）	<br>
论文链接：https://arxiv.org/abs/1909.13226	<br>
作者：Enze Xie, Peize Sun, Xiaoge Song	<br>
代码：https://github.com/xieenze/PolarMask<br>
论文解读：https://zhuanlan.zhihu.com/p/84890413<br><br>

**8. xMUDA: Cross-Modal Unsupervised Domain Adaptation for 3D Semantic Segmentation**（图像分割）	<br>
论文链接：https://arxiv.org/abs/1911.12676	<br>
作者：Maximilian Jaritz, Tuan-Hung Vu, Raoul de Charette	<br><br>

**7. BlendMask: Top-Down Meets Bottom-Up for Instance Segmentation**（图像分割）	<br>
论文链接：https://arxiv.org/abs/2001.00309	<br>
作者：Hao Chen, Kunyang Sun, Zhi Tian, Chunhua Shen, Yongming Huang, Youliang Yan	<br><br>

**6. Towards Robust Image Classification Using Sequential Attention Models**（图像分类）	<br>
论文链接：https://arxiv.org/abs/1912.02184	<br>
作者：Daniel Zoran, Mike Chrzanowski, Po-Sen Huang, Sven Gowal, Alex Mott, Pushmeet Kohl	<br><br>

**5. Unsupervised Reinforcement Learning of Transferable Meta-Skills for Embodied Navigation**（无监督）<br>
论文链接：https://arxiv.org/pdf/1911.07450	<br>
作者：Juncheng Li, Xin Wang, Siliang Tang1 Haizhou Shi	<br><br>

**4. Improved Few-Shot Visual Classification**（小样本）	<br>
论文链接：https://arxiv.org/pdf/1912.03432.pdf	<br>
作者：Peyman Bateni, Raghav Goyal, Vaden Masrani	<br><br>

**3. Multi-Modal Domain Adaptation for Fine-Grained Action Recognition**（姿态估计）	<br>
论文链接：https://arxiv.org/abs/2001.09691	<br>
作者：Jonathan Munro, Dima Damen	<br><br>

**2. Distribution Aware Coordinate Representation for Human Pose Estimation**姿态估计	<br>
论文链接：https://arxiv.org/abs/1910.06278	<br>
作者：Feng Zhang, Xiatian Zhu	<br>
代码：https://github.com/ilovepose/DarkPose<br><br>

**1. The Devil is in the Details: Delving into Unbiased Data Processing for Human Pose Estimation**	姿态估计	<br>
论文链接：https://arxiv.org/abs/1911.07524	<br>
作者：Junjie Huang, Zheng Zhu, Feng Guo, Guan Huang	<br>
论文解读：https://mp.weixin.qq.com/s/J1Y0tSIpfTOZ4J-9PPyhag<br><br>


# 2.CVPR2020论文解读（持续更新）<br>



### [14.CVPR2020 | 最新最完善的场景图生成 (SGG)开源框架，集成目前最全metrics，已开源](https://mp.weixin.qq.com/s/Nj6GjpRG8qG1ihhcoY9SwQ)<br>
选择2019年热门框架facebookresearch/maskrcnn-benchmark作为基础，在其基础上搭建了Scene-Graph-Benchmark.pytorch。该代码不仅兼容了maskrcnn-benchmark所支持的所有detector模型，且得益于facebookresearch优秀的代码功底，更大大增加了SGG部分的可读性和可操作性。<br>
论文链接：https://arxiv.org/abs/2002.11949<br>
论文代码：https://github.com/KaihuaTang/Scene-Graph-Benchmark.pytorch<br><br>


### [13.CVPR2020 | 旷视研究院提出基于3D关键点投票网络的单目6DoF位姿估计算法(已开源)](https://mp.weixin.qq.com/s/c8rQYj5lSOtI1iza9e0Dpw)<br>
论文链接：https://arxiv.org/abs/1911.04231<br>
论文代码：https://github.com/ethnhe/PVN3D.git<br>
旷视研究院提出一种基于霍夫投票（Hough voting)的 3D 关键点检测神经网络，称之为 PVN3D，以学习逐点到 3D 关键点的偏移并为 3D 关键点投票。把基于 2D 关键点的方法推进至 3D 关键点，以充分利用刚体的几何约束信息，极大提升了 6DoF 估计的精确性。在 YCB-Video 和 LineMOD 两大公开数据集上进行了评估实验，结果表明该方法以大幅优势取得了当前最佳性能。
<br><br>


### [12.跨模态行人重识别：共享与特异特征变换算法cm-SSFT](https://mp.weixin.qq.com/s/qPc71o2JeMDpDgRxDtp2BA)<br>
论文链接：https://arxiv.org/abs/2002.12489<br>
关注红外线-RGB跨模态行人重识别。试图解决：以往大部分跨模态行人重识别算法一般都只关注shared feature learning，而很少关注Specific feature。因为Specific feature在对面模态中是不存在的。例如在红外线图片中是没有彩色颜色信息的。反之在彩图中也不会有热度信息。而实际上做过ReID的都知道，传统ReID之所以性能很高，很大程度上就是有些“过拟合”到了这些specific信息上。比如衣服颜色一直是传统ReID的一个重要的cue。从这个角度出发，尝试利用specific特征。主要思路是利用近邻信息：给定一红外线query。当搜索彩色target时，可以先找到一些简单的置信度高的彩色样本（这些样本大概率是红外线query的positive样本），把这些彩色样本的颜色特异特征给与红外线query。做了这件事后，红外线query样本可以利用这些彩色信息再去搜索更难的彩色样本。<br><br>

### [11.RandLA-Net:大场景三维点云语义分割新框架（已开源）](https://mp.weixin.qq.com/s/xuLJ8m_ipGVBXVduA7Y0IA)<br>
论文链接：https://arxiv.org/abs/1911.11236<br>
代码：https://github.com/QingyongHu/RandLA-Net<br>
提出了一种基于简单高效的随机降采样和局部特征聚合的网络结构(RandLA-Net)。该方法不仅在诸如Semantic3D和SemanticKITTI等大场景点云分割数据集上取得了非常好的效果，并且具有非常高的效率(e.g. 比基于图的方法SPG快了接近200倍)。<br><br>


### [10.腾讯推出超强少样本目标检测算法，公开千类少样本检测训练集FSOD](https://mp.weixin.qq.com/s/TRRsBGzMir0ttzjTdXwJCw)<br>
论文链接：https://arxiv.org/abs/1908.01998<br>
提出了新的少样本目标检测算法，创新点包括Attention-RPN、多关系检测器以及对比训练策略，另外还构建了包含1000类的少样本检测数据集FSOD，在FSOD上训练得到的论文模型能够直接迁移到新类别的检测中，不需要fine-tune<br><br>

### [9.CARS: 华为提出基于进化算法和权值共享的神经网络结构搜索，CIFAR-10上仅需单卡半天](https://mp.weixin.qq.com/s/GAL-hbERLp6vS2zB_I9jxg)
<br>
论文链接：https://arxiv.org/abs/1909.04977<br>
为了优化进化算法在神经网络结构搜索时候选网络训练过长的问题，参考ENAS和NSGA-III，论文提出连续进化结构搜索方法(continuous evolution architecture search, CARS)，最大化利用学习到的知识，如上一轮进化的结构和参数。首先构造用于参数共享的超网，从超网中产生子网，然后使用None-dominated排序策略来选择不同大小的优秀网络，整体耗时仅需要0.5 GPU day。<br><br>

### [8.化繁为简，弱监督目标定位领域的新SOTA - 伪监督目标定位方法(PSOL)](https://mp.weixin.qq.com/s/6G7BG8DrKZ0Zvi-BUqg78w)<br>

论文链接：https://arxiv.org/abs/2002.11359<br>
论文提出伪监督目标定位方法(PSOL)来解决目前弱监督目标定位方法的问题，该方法将定位与分类分开成两个独立的网络，然后在训练集上使用Deep descriptor transformation(DDT)生成伪GT进行训练，整体效果达到SOTA。 该论文主要有三点贡献：一、弱监督目标定位应该分为类不可知目标定位和目标分类两个独立的部分，提出PSOL算法；二、尽管生成的bbox有偏差，论文仍然认为应该直接优化他们而不需要类标签，最终达到SOTA；三、在不同的数据集上，PSOL算法不需要fine-tuning也能有很好的定位迁移能力<br><br>


### [7.字节跳动：基于解剖学感知的视频3D人体姿态估计](https://mp.weixin.qq.com/s/ut8CmEZPc3NMDdlgXfUzGg)<br>

论文链接：https://arxiv.org/pdf/2002.10322.pdf<br>
在这项工作中，我们提出了一种新的视频中3D人体姿态估计的解决方案。我们不是直接回归3D关节位置，而是从人体骨骼解剖中汲取灵感，将任务分解为骨骼方向预测和骨骼长度预测，从这两个预测中完全可以得到三维关节位置。我们的研究动机是人类骨骼的长度随着时间的推移保持一致。这推动了我们开发有效的技术来利用视频中所有帧的全局信息来进行高精度的骨骼长度预测。此外，对于骨骼方向预测网络，我们提出了一种具有长跳跃连接的全卷积传播结构。本质上，它分层地预测不同骨骼的方向，而不使用任何耗时的存储单元(例如LSTM)。进一步引入了一种新的关节位移损失来连接骨骼长度和骨骼方向预测网络的训练。最后，我们采用一种隐含的注意机制将2D关键点可见性分数作为额外的指导反馈到模型中，这显著地缓解了许多具有挑战性的姿势中的深度歧义。我们的完整模型在Human3.6M和MPI-INF-3dHP数据集上的表现优于之前的最好结果，在这些数据集上的综合评估验证了我们模型的有效性。<br><br>


### [6.微软亚洲研究院：给Deepfake 假脸做 X-Ray，新模型把换脸图打回原形](https://mp.weixin.qq.com/s/DLxqGFm6IRffPa8A0XBc4w)<br>

论文链接：论文地址：https://arxiv.org/pdf/1912.13458.pdf<br>
微软亚洲研究院提出了一个方法，它既不需要了解换脸后的图像数据，也不需要知道换脸算法，就能对图像做『X-Ray』，鉴别出是否换脸，以及指出换脸的边界。
新模型 Face X-Ray 具有两大属性：能泛化到未知换脸算法、能提供可解释的换脸边界。要获得这样的优良属性，诀窍就藏在换脸算法的一般过程中。如下所示，大多数换脸算法可以分为检测、修改以及融合三部分。与之前的研究不同，Face X-Ray 希望检测第三阶段产生的误差。<br><br>

### [5.UDP：人体姿态估计中的无偏数据处理方法](https://mp.weixin.qq.com/s/J1Y0tSIpfTOZ4J-9PPyhag)<br>

论文链接：https://arxiv.org/abs/1911.07524<br>
UDP，解决了现有的SOTA人体姿态估计算法中标准编解码方法存在较大统计误差的问题。同时解决了由于翻转测试而导致的结果不对齐问题。且该算法即用即插，在基本不增加模型复杂度的情况下，有效提升了算法性能。<br><br>

### [4.让合成图像更真实，上交大提出基于域验证的图像和谐化](https://mp.weixin.qq.com/s/JgQ7bgc_bfgWE-PmJMKtOA)<br>

论文链接：https://arxiv.org/abs/1911.13239<br>
在合成图中，前景和背景是在不同的拍摄条件 (比如时刻、季节、光照、天气) 下拍摄的，所以在亮度色泽等方面存在明显的不匹配问题。图像和谐化 (image harmonization) 旨在调整合成图中的前景，使其与背景和谐。传统的图像和谐化方法一般是从背景或者其他图片转移颜色信息到前景上，但这样无法保证调整之后的前景看起来真实并且与背景和谐。近年来，已经有少量的工作尝试用深度学习做图像和谐化，但成对的合成图和真实图极难获得。如果没有成对的合成图和真实图，深度学习的训练过程缺乏足够强的监督信息，合成图和谐化之后的结果也没有 ground-truth 用于评测。截至目前还没有公开的大规模图像和谐化数据库，我们**构建并公布了由四个子数据库组成的图像和谐化数据库。并且，我们提出了域验证 (domain verification) 的概念，尝试了基于域验证的图像和谐化算法。**<br><br>

### [3.PolarMask: 一阶段实例分割新思路](https://zhuanlan.zhihu.com/p/84890413)<br>

论文链接：https://arxiv.org/abs/1909.13226<br>
PolarMask基于FCOS，把实例分割统一到了FCN的框架下。FCOS本质上是一种FCN的dense prediction的检测框架，可以在性能上不输anchor based的目标检测方法，让行业看到了anchor free方法的潜力。接下来要解决的问题是实例分割。本工作最大的贡献在于把更复杂的实例分割问题，转化成在网络设计和计算量复杂度上和物体检测一样复杂的任务，把对实例分割的建模变得简单和高效。<br><br>

### [2.华为GhostNet，超越谷歌MobileNet，已开源](https://mp.weixin.qq.com/s/Wg_BQpo_3K_fumeelDvUxA)<br>

论文链接：https://arxiv.org/abs/1911.11907<br>
该论文提供了一个全新的Ghost模块，旨在通过廉价操作生成更多的特征图。基于一组原始的特征图，作者应用一系列线性变换，以很小的代价生成许多能从原始特征发掘所需信息的“幻影”特征图（Ghost feature maps）。该Ghost模块即插即用，通过堆叠Ghost模块得出Ghost bottleneck，进而搭建轻量级神经网络——GhostNet。在ImageNet分类任务，GhostNet在相似计算量情况下Top-1正确率达75.7%，高于MobileNetV3的75.2%。<br><br>

### [1.加州理工大学Devi Parikh：多任务视觉和语言表示学习](https://mp.weixin.qq.com/s/8CvUT9JvnysIXay7vyY16w)<br>

论文链接：https://arxiv.org/abs/1912.02315<br>
许多视觉和语言的研究集中在一组小而多样的独立任务和支持的数据集上，这些数据集通常是单独研究的;然而，成功完成这些任务所需的视觉语言理解技能有很大的重叠。在这项工作中，我们通过开发一个大规模的、多任务的训练机制来研究视觉和语言任务之间的关系。<br><br>

# 3.To do list<br>
* CVPR2020复现代码及时更新<br>
* CVPR2020论文分享跟进<br>

<br>


# 4.Related links<br>
* [CVPR2019/2018/2017最全资料下载（论文／代码等)](https://github.com/extreme-assistant/cvpr2020/blob/master/README.md)<br>
* https://github.com/extreme-assistant/iccv2019<br><br>


# 5.CVPR2020 contributors Wechat Group<br>
为了让大家更好得进行交流，极市特别组建了贡献者群及作者微信群，欢迎加小助手微信（cv-mart，备注CVPR2020）进群。
