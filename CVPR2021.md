# CVPR2021最新信息及论文下载贴（Papers/Codes/Project/PaperReading／Demos/直播分享／论文分享会等）

官网链接：http://cvpr2021.thecvf.com<br>
时间：2021年6月19日-6月25日<br>
论文接收公布时间：2021年2月28日<br>

相关问题：<br>

* [如何评价CVPR 2021的论文接收结果？](https://www.zhihu.com/question/446299297)<br>
* [CVPR 2021接收结果出炉！录用1663篇，接受率提升，你的论文中了吗？（附论文下载）](https://mp.weixin.qq.com/s/4UQ2W1V-eLnL02L8BDOtMg)

<br><br>

# 目录

[1. CVPR2021接受论文/代码（持续更新）](#1)<br>
[2. To do list](#2)


<br>

<a name="1"/> 

## 1.CVPR2021接受论文/代码(持续更新)

28.D-NeRF: Neural Radiance Fields for Dynamic Scenes(D-NeRF：动态场景的神经辐射场)<br>
[project](https://t.co/lO77rqzyti?amp=1)<br><br>

27.Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation(样式编码：用于图像到图像翻译的StyleGAN编码器)<br>
[project](https://eladrich.github.io/pixel2style2pixel/)<br><br>

26.A 3D GAN for Improved Large-pose Facial Recognition(用于改善大姿势面部识别的3D GAN)<br>
[paper](https://arxiv.org/pdf/2012.10545.pdf)<br><br>

25.Multi-Stage Progressive Image Restoration<br>
[paper](https://arxiv.org/pdf/2102.02808.pdf)<br><br>

24.Rotation Equivariant Siamese Networks for Tracking（旋转等距连体网络进行跟踪）<br>
[paper](https://arxiv.org/abs/2012.13078)<br><br>

23.Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning(探索少量学习的不变表示形式和等变表示形式的互补强度)<br><br>

22.Open-world object detection(开放世界中的目标检测)<br>
[code](https://t.co/LjYSdMNLhK?amp=1)<br><br>

21.Multi-Stage Progressive Image Restoration(多阶段渐进式图像复原)<br>
[paper](https://arxiv.org/abs/2102.02808)|[code](https://github.com/swz30/MPRNet)<br><br>

20.Weakly Supervised Learning of Rigid 3D Scene Flow(刚性3D场景流的弱监督学习)<br>
[paper](https://arxiv.org/pdf/2102.08945.pdf)|[code](https://arxiv.org/pdf/2102.08945.pdf)|[project](https://3dsceneflow.github.io/)<br><br>

19.PREDATOR: Registration of 3D Point Clouds with Low Overlap(预测器：低重叠的3D点云的注册)<br>
[paper](https://arxiv.org/pdf/2011.13005.pdf)|[code](https://github.com/ShengyuH/OverlapPredator)|[project](https://overlappredator.github.io/)<br><br>

18.Sequential Graph Convolutional Network for Active Learning(主动学习的顺序图卷积网络)<br>
[paper](https://arxiv.org/pdf/2006.10219.pdf)<br><br>

17.Multiresolution Knowledge Distillation for Anomaly Detection(用于异常检测的多分辨率知识蒸馏)<br>
[paper](https://arxiv.org/abs/2011.11108)<br><br>

16.Positive-Unlabeled Data Purification in the Wild for Object Detection<br><br>

15.Data-Free Knowledge Distillation For Image Super-Resolution(DAFL算法的SR版本)<br><br>

14.Manifold Regularized Dynamic Network Pruning（动态剪枝的过程中考虑样本复杂度与网络复杂度的约束）<br><br>

13.Distilling Object Detectors via Decoupled Features（前景背景分离的蒸馏技术） <br><br>

12.Inverting the Inherence of Convolution for Visual Recognition<br><br>

11.Representative Batch Normalization with Feature Calibration<br><br>

10.PointFlow: Flowing Semantics Through Points for Aerial Image Segmentation<br><br>

9.Learning the Superpixel in a Non-iterative and Lifelong Manner<br><br>

8.RepVGG: Making VGG-style ConvNets Great Again<br>
[paper](https://arxiv.org/abs/2101.03697)|[code](https://github.com/megvii-model/RepVGG)<br>
解读：[RepVGG：极简架构，SOTA性能，让VGG式模型再次伟大](https://zhuanlan.zhihu.com/p/344324470)<br><br>

7.Transformer Interpretability Beyond Attention Visualization<br>
[paper](https://arxiv.org/pdf/2012.09838.pdf)<br><br>

6.UP-DETR: Unsupervised Pre-training for Object Detection with Transformers<br>
[paper](https://arxiv.org/pdf/2011.09094.pdf)<br>
解读：[无监督预训练检测器](https://www.zhihu.com/question/432321109/answer/1606004872)<br><br>

5.Pre-Trained Image Processing Transformer(底层视觉预训练模型)<br>
[paper](https://arxiv.org/pdf/2012.00364.pdf)<br><br>

4.ReNAS: Relativistic Evaluation of Neural Architecture Search(NAS predictor当中ranking loss的重要性)<br>
[paper](https://arxiv.org/pdf/1910.01523.pdf)<br><br>

3.AdderSR: Towards Energy Efficient Image Super-Resolution(将加法网路应用到图像超分辨率中)<br>
[paper](https://arxiv.org/pdf/2009.08891.pdf)|[code](https://github.com/huawei-noah/AdderNet)<br>
解读：[华为开源加法神经网络](https://zhuanlan.zhihu.com/p/113536045)<br><br>

2.Learning Student Networks in the Wild（一种不需要原始训练数据的模型压缩和加速技术）<br>
[paper](https://arxiv.org/pdf/1904.01186.pdf)|[code](https://github.com/huawei-noah/DAFL)<br>
解读：[华为诺亚方舟实验室提出无需数据网络压缩技术](https://www.zhihu.com/question/446299297)<br><br>

1.HourNAS: Extremely Fast Neural Architecture Search Through an Hourglass Lens（降低NAS的成本）<br>
[paper](https://arxiv.org/pdf/2005.14446.pdf)<br><br>



<br>

<a name="2"/> 

## 2.To do list

* CVPR2021论文解读
* CVPR2021 Oral
* CVPR2021论文分享
